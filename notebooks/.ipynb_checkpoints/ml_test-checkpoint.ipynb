{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.2.9.108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteJSON(obj,filename):\n",
    "    with open(filename, 'w+') as outfile:\n",
    "        try:\n",
    "            obj_json = json.dumps(obj, sort_keys=True, indent=4,default=str)\n",
    "            outfile.write(obj_json)\n",
    "        except Exception as e:\n",
    "            print(e, file=sys.stderr)\n",
    "            print('File not written.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadJSON(filename):\n",
    "    obj = []\n",
    "    try: \n",
    "        with open(filename, 'r') as infile:\n",
    "            obj = json.load(infile)\n",
    "    except Exception as e:\n",
    "        print(e, file=sys.stderr)\n",
    "        print('File not found.')\n",
    "        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FitAndScoreCLA(features,labels,classifiers,testSize=0.20):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,labels,test_size = testSize, random_state=42)\n",
    "    \n",
    "    clfs = []\n",
    "    for classifier in classifiers:\n",
    "        tmp = {}\n",
    "        clf = classifier['Method']\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Get report and matrix for display\n",
    "        print('Classification report for  -',classifier['Name'])\n",
    "        print('-----------------------------------------------------------------------------------------------')\n",
    "        print(\" %s:\\n%s\\n\"% (clf, classification_report(y_test, y_pred)))\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "        print(classifier['Name'],'Confusion Matrix')\n",
    "        print('   P0 \\t P1 ')\n",
    "        print('A0',tn,'\\t',fp)\n",
    "        print('A1',fn,'\\t',tp)\n",
    "        print('\\n')\n",
    "        \n",
    "        print('r^2: ',r2)\n",
    "        \n",
    "        # Get report and matrix for file\n",
    "        clr = classification_report(y_test, y_pred,output_dict=True)\n",
    "        cnm = list(confusion_matrix(y_test,y_pred))\n",
    "        \n",
    "        tmp[classifier['Name']] = {'Report':clr,\n",
    "                                  'Matrix':cnm}\n",
    "        clfs.append(tmp)  \n",
    "        \n",
    "    # Open results file, append new result, write to file\n",
    "    resultsObj = ReadJSON(results_file)\n",
    "    \n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    \n",
    "    currResults = {'Description':description,\n",
    "                   'classifiers':clfs,\n",
    "                   'Run Time':date_time,\n",
    "                   'Sample Size':sample_size,\n",
    "                   'Image Resolution':img_size,\n",
    "                   'Counts':{'0':dict(df.Catenary.value_counts())[0],'1':dict(df.Catenary.value_counts())[1]},\n",
    "              }\n",
    "    \n",
    "    resultsObj.append(currResults)\n",
    "    WriteJSON(resultsObj,results_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters \n",
    "----------\n",
    "Set for each test. \n",
    "\n",
    "\n",
    "img_folder: Root folder of image collection\n",
    "\n",
    "results_file: JSON file for output of results and metadata\n",
    "\n",
    "description: String for labeling/notes\n",
    "\n",
    "sample_size: Sample size to pull from each csv, 0-1\n",
    "\n",
    "img_size: Native resolution is 1280x1280\n",
    "\n",
    "'''\n",
    "\n",
    "img_folder = '../data/output_images/'\n",
    "\n",
    "results_file = '../data/results/'+'results3.json'\n",
    "\n",
    "description = 'All ten image sets. Three quarters resolution.'\n",
    "\n",
    "sample_size = .50\n",
    "\n",
    "img_size = (640,640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File b'../data/output_images/China/CHN.csv' does not exist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Catenary</th>\n",
       "      <th>Railway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153.062465_-27.421940999999997</td>\n",
       "      <td>153.062465</td>\n",
       "      <td>-27.421941</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145.0420405_-37.889686</td>\n",
       "      <td>145.042041</td>\n",
       "      <td>-37.889686</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153.01665319999998_-27.463711100000005</td>\n",
       "      <td>153.016653</td>\n",
       "      <td>-27.463711</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.1964198_-33.868837</td>\n",
       "      <td>151.196420</td>\n",
       "      <td>-33.868837</td>\n",
       "      <td>0</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145.08249840000002_-37.8592985</td>\n",
       "      <td>145.082498</td>\n",
       "      <td>-37.859299</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name   Longitude   Latitude  Catenary  \\\n",
       "0          153.062465_-27.421940999999997  153.062465 -27.421941         1   \n",
       "1                  145.0420405_-37.889686  145.042041 -37.889686         1   \n",
       "2  153.01665319999998_-27.463711100000005  153.016653 -27.463711         1   \n",
       "3                  151.1964198_-33.868837  151.196420 -33.868837         0   \n",
       "4          145.08249840000002_-37.8592985  145.082498 -37.859299         1   \n",
       "\n",
       "     Railway  \n",
       "0  Australia  \n",
       "1  Australia  \n",
       "2  Australia  \n",
       "3  Australia  \n",
       "4  Australia  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Loads csv only, no images.\n",
    "'''\n",
    "\n",
    "# Name of folder\n",
    "names = [\n",
    "    'Australia',\n",
    "    'China',\n",
    "    'Germany',\n",
    "    'NewarkLR',\n",
    "    'Switzerland',\n",
    "    'Amtrak',\n",
    "    'BostonMTBA',\n",
    "    'DenverRTD',\n",
    "    'LosAngelesMR',\n",
    "    'SeattleLLR',\n",
    "    'Netherlands'\n",
    "]\n",
    "\n",
    "# Name of csv\n",
    "abbr = [\n",
    "    'AUS',\n",
    "    'CHN',\n",
    "    'GRM',\n",
    "    'NEW',\n",
    "    'SWZ',\n",
    "    'AMT',\n",
    "    'BOS',\n",
    "    'DEN',\n",
    "    'LAA',\n",
    "    'SEA',\n",
    "    'NET'\n",
    "]\n",
    "locations = dict(zip(names,abbr))\n",
    "\n",
    "# Collect each csv into one df adding railway name\n",
    "frames = []\n",
    "for key,value in locations.items():\n",
    "    try:\n",
    "        filename = img_folder+key+'/'+value+'.csv'\n",
    "        tmp = pd.read_csv(filename,header=0)\n",
    "        tmp['Railway'] = key\n",
    "        \n",
    "        # Take sample from each folder \n",
    "        tmp = tmp.sample(frac=sample_size).reset_index(drop=True)\n",
    "        frames.append(tmp)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "df = pd.concat(frames)\n",
    "\n",
    "df = df.dropna()\n",
    "df['Catenary'] = df['Catenary'].astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    157\n",
       "0     86\n",
       "Name: Catenary, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Catenary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Open known non-catenary lines and add differntial to df\n",
    "'''\n",
    "\n",
    "zeros = df.Catenary.value_counts()[0]\n",
    "ones = df.Catenary.value_counts()[1]\n",
    "\n",
    "names = [\n",
    "    'Amtrak_non_cat_1',\n",
    "    'Amtrak_non_cat_2',\n",
    "    'Amtrak_non_cat_3'\n",
    "]\n",
    "\n",
    "abbr = [\n",
    "    'ANC',\n",
    "    'ANC2',\n",
    "    'ANC3'\n",
    "]\n",
    "locations = dict(zip(names,abbr))\n",
    "\n",
    "diff = ones - zeros\n",
    "\n",
    "if diff > 0:\n",
    "    frames = []\n",
    "    for key,value in locations.items():\n",
    "        try:\n",
    "            filename = img_folder+key+'/'+value+'.csv'\n",
    "            tmp = pd.read_csv(filename,header=0)\n",
    "            tmp['Railway'] = key\n",
    "            frames.append(tmp)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    try:\n",
    "        duds = pd.concat(frames)\n",
    "        duds = duds.dropna()\n",
    "        duds['Catenary'] = duds['Catenary'].astype(int) \n",
    "        \n",
    "        duds = duds.sample(n=diff).reset_index(drop=True)\n",
    "        df = pd.concat([df,duds]).reset_index(drop=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        duds = duds.sample(len(duds.index.tolist())).reset_index(drop=True)\n",
    "        df = pd.concat([df,duds]).reset_index(drop=True)\n",
    "        \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    157\n",
       "0    157\n",
       "Name: Catenary, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Catenary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Catenary</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[79, 71, 64, 255, 80, 74, 64, 255, 92, 86, 79,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[147, 158, 151, 255, 153, 164, 155, 255, 158, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[80, 80, 80, 255, 85, 87, 87, 255, 85, 88, 88,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[61, 62, 58, 255, 65, 63, 65, 255, 50, 51, 54,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[39, 43, 27, 255, 27, 29, 16, 255, 64, 65, 54,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Catenary                                              Image\n",
       "0         1  [79, 71, 64, 255, 80, 74, 64, 255, 92, 86, 79,...\n",
       "1         1  [147, 158, 151, 255, 153, 164, 155, 255, 158, ...\n",
       "2         1  [80, 80, 80, 255, 85, 87, 87, 255, 85, 88, 88,...\n",
       "3         0  [61, 62, 58, 255, 65, 63, 65, 255, 50, 51, 54,...\n",
       "4         1  [39, 43, 27, 255, 27, 29, 16, 255, 64, 65, 54,..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Load images into df\n",
    "'''\n",
    "rows = df.index.tolist()\n",
    "\n",
    "images = []\n",
    "for row in rows:\n",
    "    img_path = img_folder+df.iloc[row]['Railway']+'/'+df.iloc[row]['Name']+'.png'\n",
    "    img = Image.open(img_path).convert('RGBA')\n",
    "    img.thumbnail(img_size, Image.ANTIALIAS)\n",
    "    data = np.asarray(img)\n",
    "    data = data.flatten()\n",
    "    # Append img instead of data if you want as image       \n",
    "    images.append(data)\n",
    "    \n",
    "df['Image'] = images\n",
    "\n",
    "cols = ['Catenary','Image']\n",
    "df = df[cols]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(df.Catenary.tolist())\n",
    "features = np.asarray(df.Image.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Setup classifiers\n",
    "'''\n",
    "\n",
    "BGN = {'Name':'BGN',\n",
    "       'Method': GaussianNB()}\n",
    "\n",
    "DTC = {'Name':'DTC',\n",
    "       'Method': DecisionTreeClassifier()}\n",
    "\n",
    "KNN = {'Name':'KNN',\n",
    "       'Method': KNeighborsClassifier()}\n",
    "\n",
    "SVM = {'Name':'SVM',\n",
    "       'Method': SVC(gamma=0.001)}\n",
    "\n",
    "\n",
    "classifiers = [BGN,DTC,KNN,SVM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for  - BGN\n",
      "-----------------------------------------------------------------------------------------------\n",
      " GaussianNB(priors=None, var_smoothing=1e-09):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.45      0.51        31\n",
      "           1       0.56      0.69      0.62        32\n",
      "\n",
      "   micro avg       0.57      0.57      0.57        63\n",
      "   macro avg       0.57      0.57      0.56        63\n",
      "weighted avg       0.57      0.57      0.57        63\n",
      "\n",
      "\n",
      "BGN Confusion Matrix\n",
      "   P0 \t P1 \n",
      "A0 14 \t 17\n",
      "A1 10 \t 22\n",
      "\n",
      "\n",
      "r^2:  -0.7147177419354835\n",
      "Classification report for  - DTC\n",
      "-----------------------------------------------------------------------------------------------\n",
      " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.52      0.54        31\n",
      "           1       0.57      0.62      0.60        32\n",
      "\n",
      "   micro avg       0.57      0.57      0.57        63\n",
      "   macro avg       0.57      0.57      0.57        63\n",
      "weighted avg       0.57      0.57      0.57        63\n",
      "\n",
      "\n",
      "DTC Confusion Matrix\n",
      "   P0 \t P1 \n",
      "A0 16 \t 15\n",
      "A1 12 \t 20\n",
      "\n",
      "\n",
      "r^2:  -0.7147177419354835\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3615a3497a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mFitAndScoreCLA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-e6b7cf4e65b3>\u001b[0m in \u001b[0;36mFitAndScoreCLA\u001b[0;34m(features, labels, classifiers, testSize)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Method'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gis/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gis/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    256\u001b[0m             self._tree = KDTree(X, self.leaf_size,\n\u001b[1;32m    257\u001b[0m                                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                                 **self.effective_metric_params_)\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'brute'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Run Classifier\n",
    "'''\n",
    "\n",
    "FitAndScoreCLA(features,labels,classifiers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
