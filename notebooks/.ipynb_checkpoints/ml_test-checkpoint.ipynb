{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.2.9.20\n",
    "#  cd ../../media/nvidia/Mercyhurst/wabtec/rail_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteJSON(obj,filename):\n",
    "    with open(filename, 'w+') as outfile:\n",
    "        try:\n",
    "            obj_json = json.dumps(obj, sort_keys=True, indent=4,default=str)\n",
    "            outfile.write(obj_json)\n",
    "        except Exception as e:\n",
    "            print(e, file=sys.stderr)\n",
    "            print('File not written.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadJSON(filename):\n",
    "    obj = []\n",
    "    try: \n",
    "        with open(filename, 'r') as infile:\n",
    "            obj = json.load(infile)\n",
    "    except Exception as e:\n",
    "        print(e, file=sys.stderr)\n",
    "        print('File not found.')\n",
    "        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FitAndScoreCLA(features,labels,classifiers,testSize=0.20):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,labels,test_size = testSize, random_state=42)\n",
    "    \n",
    "    clfs = []\n",
    "    for classifier in classifiers:\n",
    "        tmp = {}\n",
    "        clf = classifier['Method']\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Get report and matrix for display\n",
    "        print('Classification report for  -',classifier['Name'])\n",
    "        print('-----------------------------------------------------------------------------------------------')\n",
    "        print(\" %s:\\n%s\\n\"% (clf, classification_report(y_test, y_pred)))\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "        print(classifier['Name'],'Confusion Matrix')\n",
    "        print('   P0 \\t P1 ')\n",
    "        print('A0',tn,'\\t',fp)\n",
    "        print('A1',fn,'\\t',tp)\n",
    "        print('\\n')\n",
    "        \n",
    "        print('r^2: ',r2)\n",
    "        \n",
    "        # Get report and matrix for file\n",
    "        clr = classification_report(y_test, y_pred,output_dict=True)\n",
    "        cnm = list(confusion_matrix(y_test,y_pred))\n",
    "        \n",
    "        tmp[classifier['Name']] = {'Report':clr,\n",
    "                                  'Matrix':cnm}\n",
    "        clfs.append(tmp)  \n",
    "        \n",
    "    # Open results file, append new result, write to file\n",
    "    resultsObj = ReadJSON(results_file)\n",
    "    \n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    \n",
    "    currResults = {'Description':description,\n",
    "                   'classifiers':clfs,\n",
    "                   'Run Time':date_time,\n",
    "                   'Sample Size':sample_size,\n",
    "                   'Image Resolution':img_size,\n",
    "                   'Counts':{'0':dict(df.Catenary.value_counts())[0],'1':dict(df.Catenary.value_counts())[1]},\n",
    "              }\n",
    "    \n",
    "    resultsObj.append(currResults)\n",
    "    WriteJSON(resultsObj,results_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters \n",
    "----------\n",
    "Set for each test. \n",
    "\n",
    "\n",
    "img_folder: Root folder of image collection\n",
    "\n",
    "results_file: JSON file for output of results and metadata\n",
    "\n",
    "description: String for labeling/notes\n",
    "\n",
    "sample_size: Sample size to pull from each csv, 0-1\n",
    "\n",
    "img_size: Native resolution is 1280x1280\n",
    "\n",
    "'''\n",
    "\n",
    "img_folder = '../data/output_images/'\n",
    "\n",
    "img_set = '2'\n",
    "\n",
    "results_file = '../data/results/'+'results3.json'\n",
    "\n",
    "description = 'All ten image sets. Full resolution.'\n",
    "\n",
    "sample_size = 1.0\n",
    "\n",
    "img_size = (640,640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Catenary</th>\n",
       "      <th>Railway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153.0843907_-27.4297185</td>\n",
       "      <td>153.084391</td>\n",
       "      <td>-27.429718</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153.0331517_-27.4483646</td>\n",
       "      <td>153.033152</td>\n",
       "      <td>-27.448365</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153.01603169999998_-27.4651858</td>\n",
       "      <td>153.016032</td>\n",
       "      <td>-27.465186</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144.8900178_-37.802351200000004</td>\n",
       "      <td>144.890018</td>\n",
       "      <td>-37.802351</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.19101840000002_-33.9324425</td>\n",
       "      <td>151.191018</td>\n",
       "      <td>-33.932443</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name   Longitude   Latitude  Catenary    Railway\n",
       "0          153.0843907_-27.4297185  153.084391 -27.429718         1  Australia\n",
       "1          153.0331517_-27.4483646  153.033152 -27.448365         1  Australia\n",
       "2   153.01603169999998_-27.4651858  153.016032 -27.465186         1  Australia\n",
       "3  144.8900178_-37.802351200000004  144.890018 -37.802351         1  Australia\n",
       "4   151.19101840000002_-33.9324425  151.191018 -33.932443         1  Australia"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Loads csv only, no images.\n",
    "'''\n",
    "\n",
    "# Name of folder\n",
    "names = [\n",
    "    'Australia',\n",
    "#     'China',\n",
    "#     'Germany',\n",
    "#     'NewarkLR',\n",
    "#     'Switzerland',\n",
    "#     'Amtrak',\n",
    "#     'BostonMTBA',\n",
    "#     'DenverRTD',\n",
    "#     'LosAngelesMR',\n",
    "#     'SeattleLLR',\n",
    "#     'Netherlands'\n",
    "]\n",
    "\n",
    "# Name of csv\n",
    "abbr = [\n",
    "    'AUS',\n",
    "#     'CHN',\n",
    "#     'GRM',\n",
    "#     'NEW',\n",
    "#     'SWZ',\n",
    "#     'AMT',\n",
    "#     'BOS',\n",
    "#     'DEN',\n",
    "#     'LAA',\n",
    "#     'SEA',\n",
    "#     'NET'\n",
    "]\n",
    "locations = dict(zip(names,abbr))\n",
    "\n",
    "# Collect each csv into one df adding railway name\n",
    "frames = []\n",
    "for key,value in locations.items():\n",
    "    try:\n",
    "        filename = img_folder+key+'/'+value+'.csv'\n",
    "        tmp = pd.read_csv(filename,header=0)\n",
    "        tmp['Railway'] = key\n",
    "        \n",
    "        # Take sample from each folder \n",
    "        tmp = tmp.sample(frac=sample_size).reset_index(drop=True)\n",
    "        frames.append(tmp)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "df = pd.concat(frames)\n",
    "\n",
    "df = df.dropna()\n",
    "df['Catenary'] = df['Catenary'].astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    45\n",
       "0     5\n",
       "Name: Catenary, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Catenary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Open known non-catenary lines and add differntial to df\n",
    "'''\n",
    "\n",
    "zeros = df.Catenary.value_counts()[0]\n",
    "ones = df.Catenary.value_counts()[1]\n",
    "\n",
    "names = [\n",
    "#     'Amtrak_non_cat_1',\n",
    "#     'Amtrak_non_cat_2',\n",
    "#     'Amtrak_non_cat_3',\n",
    "    'Random'\n",
    "]\n",
    "\n",
    "abbr = [\n",
    "#     'ANC',\n",
    "#     'ANC2',\n",
    "#     'ANC3',\n",
    "    'RAN'\n",
    "]\n",
    "locations = dict(zip(names,abbr))\n",
    "\n",
    "diff = ones - zeros\n",
    "# print(diff)\n",
    "\n",
    "if diff > 0:\n",
    "    frames = []\n",
    "    for key,value in locations.items():\n",
    "        try:\n",
    "            filename = img_folder+key+'/'+value+'.csv'\n",
    "#             print(filename)\n",
    "            tmp = pd.read_csv(filename,header=0)\n",
    "            tmp['Railway'] = key\n",
    "            frames.append(tmp)\n",
    "#             print(tmp)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    try:\n",
    "        duds = pd.concat(frames)\n",
    "        duds = duds.dropna()\n",
    "        duds['Catenary'] = duds['Catenary'].astype(int) \n",
    "        \n",
    "#         print(len(duds))\n",
    "        duds = duds.sample(n=diff).reset_index(drop=True)\n",
    "        df = pd.concat([df,duds]).reset_index(drop=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        duds = duds.sample(len(duds.index.tolist())).reset_index(drop=True)\n",
    "        df = pd.concat([df,duds]).reset_index(drop=True)\n",
    "        \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    45\n",
       "0    45\n",
       "Name: Catenary, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Catenary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/YgCRCZ6RgYE.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/q-AUVMtICg0.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/NyfXy0Is4YA.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/QL6-tL7in8Y.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/XnXNWsXWG9Y.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/kTYc-gDAc-w.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/fQ-CxAhjakE.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/sSQeNMWhFHY.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/UMUCQcDdLws.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/s79i3mBakbU.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/dZr-Q9ZQ1dk.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/2TYnKYN8IgA.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/PkRS8ZahINM.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/x9zUfrqaL2I.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/O5pJux38nNA.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/JN3TwFKt7nI.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/Qyryr8O_3Wg.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/FnviBLnjppk.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/a-DETTxYhCw.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/AqoXaM9NSsw.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/RcMfDLUxTqM.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/fmoLeqdXNzE.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/NXHIri2o8B0.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/ztW4RpFvIwY.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/Z_MDa1N38ZI.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/7BVqFvkitOc.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/dQriq2v8xxc.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/XB-lg7AdSp0.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/eqFOKASP2ww.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/F7_L-91SWUs.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/YUg5CF1JyV8.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/qjZzZccbE1E.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/qZ8XBmrW0xI.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/6tq4XLpNZhU.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/Bq5GubQFIXY.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/1s7LF_mAXDo.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/2tohSrlhEso.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/mIOZ_pkasws.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/gPO83eCt0vs.png'\n",
      "[Errno 2] No such file or directory: '../data/output_images/Random/set_2/V9XdQA_Lz-8.png'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-e7c6a5994d26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Catenary'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo1/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3369\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3370\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo1/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3444\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3445\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3446\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo1/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3629\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3630\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3631\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geo1/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load images into df\n",
    "'''\n",
    "rows = df.index.tolist()\n",
    "\n",
    "images = []\n",
    "for row in rows:\n",
    "    try:\n",
    "        img_path = img_folder+df.iloc[row]['Railway']+'/set_'+img_set+'/'+df.iloc[row]['Name']+'.png'\n",
    "        img = Image.open(img_path).convert('RGBA')\n",
    "        img.thumbnail(img_size, Image.ANTIALIAS)\n",
    "        data = np.asarray(img)\n",
    "        data = data/255\n",
    "        data = data.flatten()\n",
    "        # Append img instead of data if you want as image       \n",
    "        images.append(data)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "df['Image'] = images\n",
    "\n",
    "cols = ['Catenary','Image']\n",
    "df = df[cols]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(df.Catenary.tolist())\n",
    "features = np.asarray(df.Image.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Setup classifiers\n",
    "'''\n",
    "\n",
    "BGN = {'Name':'BGN',\n",
    "       'Method': GaussianNB()}\n",
    "\n",
    "DTC = {'Name':'DTC',\n",
    "       'Method': DecisionTreeClassifier(random_state=0)}\n",
    "\n",
    "KNN = {'Name':'KNN',\n",
    "       'Method': KNeighborsClassifier()}\n",
    "\n",
    "SVM = {'Name':'SVM',\n",
    "       'Method': SVC(gamma=0.001)}\n",
    "\n",
    "\n",
    "classifiers = [DTC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run Classifier\n",
    "'''\n",
    "\n",
    "FitAndScoreCLA(features,labels,classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run Classifier\n",
    "'''\n",
    "\n",
    "FitAndScoreCLA(features,labels,classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
