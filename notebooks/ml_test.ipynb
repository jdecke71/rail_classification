{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.2.9.108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteJSON(obj,filename):\n",
    "    with open(filename, 'w+') as outfile:\n",
    "        try:\n",
    "            obj_json = json.dumps(obj, sort_keys=True, indent=4,default=str)\n",
    "            outfile.write(obj_json)\n",
    "        except Exception as e:\n",
    "            print(e, file=sys.stderr)\n",
    "            print('File not written.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadJSON(filename):\n",
    "    obj = []\n",
    "    try: \n",
    "        with open(filename, 'r') as infile:\n",
    "            obj = json.load(infile)\n",
    "    except Exception as e:\n",
    "        print(e, file=sys.stderr)\n",
    "        print('File not found.')\n",
    "        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FitAndScoreCLA(features,labels,classifiers,testSize=0.20):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,labels,test_size = testSize, random_state=42)\n",
    "    \n",
    "    clfs = []\n",
    "    for classifier in classifiers:\n",
    "        tmp = {}\n",
    "        clf = classifier['Method']\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Get report and matrix for display\n",
    "        print('Classification report for  -',classifier['Name'])\n",
    "        print('-----------------------------------------------------------------------------------------------')\n",
    "        print(\" %s:\\n%s\\n\"% (clf, classification_report(y_test, y_pred)))\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "        print(classifier['Name'],'Confusion Matrix')\n",
    "        print('   P0 \\t P1 ')\n",
    "        print('A0',tn,'\\t',fp)\n",
    "        print('A1',fn,'\\t',tp)\n",
    "        print('\\n')\n",
    "        \n",
    "        print('r^2: ',r2)\n",
    "        \n",
    "        # Get report and matrix for file\n",
    "        clr = classification_report(y_test, y_pred,output_dict=True)\n",
    "        cnm = list(confusion_matrix(y_test,y_pred))\n",
    "        \n",
    "        tmp[classifier['Name']] = {'Report':clr,\n",
    "                                  'Matrix':cnm}\n",
    "        clfs.append(tmp)  \n",
    "        \n",
    "    # Open results file, append new result, write to file\n",
    "    resultsObj = ReadJSON(results_file)\n",
    "    \n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    \n",
    "    currResults = {'Description':description,\n",
    "                   'classifiers':clfs,\n",
    "                   'Run Time':date_time,\n",
    "                   'Sample Size':sample_size,\n",
    "                   'Image Resolution':img_size,\n",
    "                   'Counts':{'0':dict(df.Catenary.value_counts())[0],'1':dict(df.Catenary.value_counts())[1]},\n",
    "              }\n",
    "    \n",
    "    resultsObj.append(currResults)\n",
    "    WriteJSON(resultsObj,results_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters \n",
    "----------\n",
    "Set for each test. \n",
    "\n",
    "\n",
    "img_folder: Root folder of image collection\n",
    "\n",
    "results_file: JSON file for output of results and metadata\n",
    "\n",
    "description: String for labeling/notes\n",
    "\n",
    "sample_size: Sample size to pull from each csv, 0-1\n",
    "\n",
    "img_size: Native resolution is 1280x1280\n",
    "\n",
    "'''\n",
    "\n",
    "img_folder = '../data/output_images/'\n",
    "\n",
    "results_file = '../data/results/'+'results3.json'\n",
    "\n",
    "description = 'All ten image sets. Three quarters resolution.'\n",
    "\n",
    "sample_size = .50\n",
    "\n",
    "img_size = (640,640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File b'../data/output_images/China/CHN.csv' does not exist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Catenary</th>\n",
       "      <th>Railway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.680897153322929_52.02627259477863</td>\n",
       "      <td>5.680897</td>\n",
       "      <td>52.026273</td>\n",
       "      <td>1</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.966978743706366_50.89235750362882</td>\n",
       "      <td>5.966979</td>\n",
       "      <td>50.892358</td>\n",
       "      <td>1</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.514447461059589_51.89960635851382</td>\n",
       "      <td>4.514447</td>\n",
       "      <td>51.899606</td>\n",
       "      <td>1</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.679545474955587_52.02653694146236</td>\n",
       "      <td>5.679545</td>\n",
       "      <td>52.026537</td>\n",
       "      <td>1</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.870732186384699_52.389796444142426</td>\n",
       "      <td>4.870732</td>\n",
       "      <td>52.389796</td>\n",
       "      <td>1</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name  Longitude   Latitude  Catenary  \\\n",
       "0   5.680897153322929_52.02627259477863   5.680897  52.026273         1   \n",
       "1   5.966978743706366_50.89235750362882   5.966979  50.892358         1   \n",
       "2   4.514447461059589_51.89960635851382   4.514447  51.899606         1   \n",
       "3   5.679545474955587_52.02653694146236   5.679545  52.026537         1   \n",
       "4  4.870732186384699_52.389796444142426   4.870732  52.389796         1   \n",
       "\n",
       "       Railway  \n",
       "0  Netherlands  \n",
       "1  Netherlands  \n",
       "2  Netherlands  \n",
       "3  Netherlands  \n",
       "4  Netherlands  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Loads csv only, no images.\n",
    "'''\n",
    "\n",
    "# Name of folder\n",
    "names = [\n",
    "    'Australia',\n",
    "    'China',\n",
    "    'Germany',\n",
    "    'NewarkLR',\n",
    "    'Switzerland',\n",
    "    'Amtrak',\n",
    "    'BostonMTBA',\n",
    "    'DenverRTD',\n",
    "    'LosAngelesMR',\n",
    "    'SeattleLLR',\n",
    "    'Netherlands'\n",
    "]\n",
    "\n",
    "# Name of csv\n",
    "abbr = [\n",
    "    'AUS',\n",
    "    'CHN',\n",
    "    'GRM',\n",
    "    'NEW',\n",
    "    'SWZ',\n",
    "    'AMT',\n",
    "    'BOS',\n",
    "    'DEN',\n",
    "    'LAA',\n",
    "    'SEA',\n",
    "    'NET'\n",
    "]\n",
    "locations = dict(zip(names,abbr))\n",
    "\n",
    "# Collect each csv into one df adding railway name\n",
    "frames = []\n",
    "for key,value in locations.items():\n",
    "    try:\n",
    "        filename = img_folder+key+'/'+value+'.csv'\n",
    "        tmp = pd.read_csv(filename,header=0)\n",
    "        tmp['Railway'] = key\n",
    "        \n",
    "        # Take sample from each folder \n",
    "        tmp = tmp.sample(frac=sample_size).reset_index(drop=True)\n",
    "        frames.append(tmp)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "df = pd.concat(frames)\n",
    "\n",
    "df = df.dropna()\n",
    "df['Catenary'] = df['Catenary'].astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    158\n",
       "0     85\n",
       "Name: Catenary, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Catenary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Open known non-catenary lines and add differntial to df\n",
    "'''\n",
    "\n",
    "zeros = df.Catenary.value_counts()[0]\n",
    "ones = df.Catenary.value_counts()[1]\n",
    "\n",
    "names = [\n",
    "    'Amtrak_non_cat_1',\n",
    "    'Amtrak_non_cat_2',\n",
    "    'Amtrak_non_cat_3'\n",
    "]\n",
    "\n",
    "abbr = [\n",
    "    'ANC',\n",
    "    'ANC2',\n",
    "    'ANC3'\n",
    "]\n",
    "locations = dict(zip(names,abbr))\n",
    "\n",
    "diff = ones - zeros\n",
    "\n",
    "if diff > 0:\n",
    "    frames = []\n",
    "    for key,value in locations.items():\n",
    "        try:\n",
    "            filename = img_folder+key+'/'+value+'.csv'\n",
    "            tmp = pd.read_csv(filename,header=0)\n",
    "            tmp['Railway'] = key\n",
    "            frames.append(tmp)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    try:\n",
    "        duds = pd.concat(frames)\n",
    "        duds = duds.dropna()\n",
    "        duds['Catenary'] = duds['Catenary'].astype(int) \n",
    "        \n",
    "        duds = duds.sample(n=diff).reset_index(drop=True)\n",
    "        df = pd.concat([df,duds]).reset_index(drop=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        duds = duds.sample(len(duds.index.tolist())).reset_index(drop=True)\n",
    "        df = pd.concat([df,duds]).reset_index(drop=True)\n",
    "        \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    158\n",
       "0    158\n",
       "Name: Catenary, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Catenary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Catenary</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[34, 46, 41, 255, 53, 64, 61, 255, 63, 75, 69,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[103, 92, 86, 255, 69, 61, 55, 255, 27, 19, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[98, 85, 82, 255, 103, 94, 92, 255, 112, 110, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[33, 35, 24, 255, 19, 28, 24, 255, 36, 36, 29,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[105, 107, 102, 255, 111, 114, 109, 255, 115, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Catenary                                              Image\n",
       "0         1  [34, 46, 41, 255, 53, 64, 61, 255, 63, 75, 69,...\n",
       "1         1  [103, 92, 86, 255, 69, 61, 55, 255, 27, 19, 16...\n",
       "2         1  [98, 85, 82, 255, 103, 94, 92, 255, 112, 110, ...\n",
       "3         1  [33, 35, 24, 255, 19, 28, 24, 255, 36, 36, 29,...\n",
       "4         1  [105, 107, 102, 255, 111, 114, 109, 255, 115, ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Load images into df\n",
    "'''\n",
    "rows = df.index.tolist()\n",
    "\n",
    "images = []\n",
    "for row in rows:\n",
    "    img_path = img_folder+df.iloc[row]['Railway']+'/'+df.iloc[row]['Name']+'.png'\n",
    "    img = Image.open(img_path).convert('RGBA')\n",
    "    img.thumbnail(img_size, Image.ANTIALIAS)\n",
    "    data = np.asarray(img)\n",
    "    data = data.flatten()\n",
    "    # Append img instead of data if you want as image       \n",
    "    images.append(data)\n",
    "    \n",
    "df['Image'] = images\n",
    "\n",
    "cols = ['Catenary','Image']\n",
    "df = df[cols]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(df.Catenary.tolist())\n",
    "features = np.asarray(df.Image.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Setup classifiers\n",
    "'''\n",
    "\n",
    "BGN = {'Name':'BGN',\n",
    "       'Method': GaussianNB()}\n",
    "\n",
    "DTC = {'Name':'DTC',\n",
    "       'Method': DecisionTreeClassifier()}\n",
    "\n",
    "KNN = {'Name':'KNN',\n",
    "       'Method': KNeighborsClassifier()}\n",
    "\n",
    "SVM = {'Name':'SVM',\n",
    "       'Method': SVC(gamma=0.001)}\n",
    "\n",
    "\n",
    "classifiers = [BGN,DTC,KNN,SVM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3615a3497a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mFitAndScoreCLA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-e6b7cf4e65b3>\u001b[0m in \u001b[0;36mFitAndScoreCLA\u001b[0;34m(features, labels, classifiers, testSize)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Method'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[0;32m--> 192\u001b[0;31m                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;31m# boost the variance by epsilon, a small fraction of the standard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;31m# deviation of the largest dimension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_smoothing\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_refit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mvar\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m   3365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3366\u001b[0m     return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0;32m-> 3367\u001b[0;31m                          **kwargs)\n\u001b[0m\u001b[1;32m   3368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# Note that x may not be inexact and that we need it to be an array,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# not a scalar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0marrmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplexfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Run Classifier\n",
    "'''\n",
    "\n",
    "FitAndScoreCLA(features,labels,classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
